{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Generate Bar Jokes.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPKbbp5vXKbvS948XhJqqlu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kinyugo/Walks_Into_A_Bar_Language_Model/blob/master/Generate_Bar_Jokes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZETQq98tbjN",
        "colab_type": "text"
      },
      "source": [
        "# Generate Bar Jokes "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zW7E8pwhubVE",
        "colab_type": "text"
      },
      "source": [
        "## Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fXihfiKuirP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import os"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkZAgHhJuoKD",
        "colab_type": "text"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OykDHJfeutT8",
        "colab_type": "text"
      },
      "source": [
        "### Fetch data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4R2KI7Euv8S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BARJOKES_TXT = \"./data/walks_into_a_bar.txt\"\n",
        "\n",
        "def transform(txt):\n",
        "  \"\"\"Transforms characters into a an array of integers.\"\"\"\n",
        "  return np.asarray([ord(c) for c in txt if ord(c) < 255], dtype=np.int32)\n",
        "\n",
        "def generate_input(seq_len=100, batch_size=1024):\n",
        "  with tf.io.gfile.GFile(BARJOKES_TXT, 'r') as f:\n",
        "    txt = f.read()\n",
        "\n",
        "  source = tf.constant(transform(txt), dtype=tf.int32)\n",
        "\n",
        "  # Generates a dataset of sequences\n",
        "  ds = tf.data.Dataset.from_tensor_slices(source).batch(seq_len+1, drop_remainder=True)\n",
        "\n",
        "  def split_input_target(chunk):\n",
        "    input_text = chunk[:-1]\n",
        "    target_text = chunk[1:]\n",
        "    return input_text, target_text\n",
        "\n",
        "  BUFFER_SIZE = 10000\n",
        "\n",
        "  # Generate batches of data from the sequences\n",
        "  ds = ds.map(split_input_target).shuffle(BUFFER_SIZE).batch(batch_size, drop_remainder=True)\n",
        "\n",
        "  return ds.repeat()\n",
        "  "
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-GyMYjvw_4S",
        "colab_type": "text"
      },
      "source": [
        "## Model Definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSVTJveOxB5x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EMBEDDING_DIM = 512\n",
        "\n",
        "def lstm_model(seq_len=100, batch_size=None, stateful=True):\n",
        "    source = tf.keras.Input(name=\"seed\", shape=(\n",
        "        seq_len,), batch_size=batch_size, dtype=tf.int32)\n",
        "    embedding = tf.keras.layers.Embedding(\n",
        "        input_dim=256, output_dim=EMBEDDING_DIM)(source)\n",
        "    lstm_1 = tf.keras.layers.LSTM(\n",
        "        EMBEDDING_DIM, stateful=stateful, return_sequences=True)(embedding)\n",
        "    lstm_2 = tf.keras.layers.LSTM(\n",
        "        EMBEDDING_DIM, stateful=stateful, return_sequences=True)(lstm_1)\n",
        "    output = tf.keras.layers.TimeDistributed(\n",
        "        tf.keras.layers.Dense(256, activation=\"softmax\"))(lstm_2)\n",
        "\n",
        "    return tf.keras.Model(inputs=[source], outputs=[output])"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQvwT-tjzCv4",
        "colab_type": "text"
      },
      "source": [
        "## Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mjK6hROzFYU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "48c78053-a220-467f-b63b-6ac052746f3e"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
        "tf.config.experimental_connect_to_cluster(resolver)\n",
        "# This is the TPU initialization code that has to be at the beginning.\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "print(\"All devices: \", tf.config.list_logical_devices('TPU'))\n",
        "\n",
        "model_path = \"bar_jokes.h5\"\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
        "    model_path, monitor=\"loss\", verbose=1, save_best_only=True, mode=\"min\")\n",
        "callbacks = [checkpoint]\n",
        "\n",
        "strategy = tf.distribute.experimental.TPUStrategy(resolver)\n",
        "\n",
        "with strategy.scope():\n",
        "  training_model = lstm_model(seq_len=100, stateful=False)\n",
        "  training_model.compile(\n",
        "      optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.01),\n",
        "      loss='sparse_categorical_crossentropy',\n",
        "      metrics=['sparse_categorical_accuracy'])\n",
        "\n",
        "training_model.fit(\n",
        "    generate_input(),\n",
        "    steps_per_epoch=100,\n",
        "    epochs=25,\n",
        "    callbacks=callbacks\n",
        ")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.43.57.194:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.43.57.194:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.43.57.194:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.43.57.194:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "All devices:  [LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:7', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:6', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:5', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:4', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:0', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:1', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:2', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:3', device_type='TPU')]\n",
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.2974 - sparse_categorical_accuracy: 0.1546\n",
            "Epoch 00001: loss improved from inf to 3.29740, saving model to bar_jokes.h5\n",
            "100/100 [==============================] - 12s 117ms/step - loss: 3.2974 - sparse_categorical_accuracy: 0.1546\n",
            "Epoch 2/25\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.9667 - sparse_categorical_accuracy: 0.4405\n",
            "Epoch 00002: loss improved from 3.29740 to 1.96669, saving model to bar_jokes.h5\n",
            "100/100 [==============================] - 12s 117ms/step - loss: 1.9667 - sparse_categorical_accuracy: 0.4405\n",
            "Epoch 3/25\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.1823 - sparse_categorical_accuracy: 0.6496\n",
            "Epoch 00003: loss improved from 1.96669 to 1.18234, saving model to bar_jokes.h5\n",
            "100/100 [==============================] - 12s 119ms/step - loss: 1.1823 - sparse_categorical_accuracy: 0.6496\n",
            "Epoch 4/25\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.8888 - sparse_categorical_accuracy: 0.7323\n",
            "Epoch 00004: loss improved from 1.18234 to 0.88884, saving model to bar_jokes.h5\n",
            "100/100 [==============================] - 12s 118ms/step - loss: 0.8888 - sparse_categorical_accuracy: 0.7323\n",
            "Epoch 5/25\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.7083 - sparse_categorical_accuracy: 0.7831\n",
            "Epoch 00005: loss improved from 0.88884 to 0.70830, saving model to bar_jokes.h5\n",
            "100/100 [==============================] - 12s 119ms/step - loss: 0.7083 - sparse_categorical_accuracy: 0.7831\n",
            "Epoch 6/25\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.5792 - sparse_categorical_accuracy: 0.8202\n",
            "Epoch 00006: loss improved from 0.70830 to 0.57917, saving model to bar_jokes.h5\n",
            "100/100 [==============================] - 12s 116ms/step - loss: 0.5792 - sparse_categorical_accuracy: 0.8202\n",
            "Epoch 7/25\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4848 - sparse_categorical_accuracy: 0.8478\n",
            "Epoch 00007: loss improved from 0.57917 to 0.48480, saving model to bar_jokes.h5\n",
            "100/100 [==============================] - 12s 116ms/step - loss: 0.4848 - sparse_categorical_accuracy: 0.8478\n",
            "Epoch 8/25\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4160 - sparse_categorical_accuracy: 0.8682\n",
            "Epoch 00008: loss improved from 0.48480 to 0.41599, saving model to bar_jokes.h5\n",
            "100/100 [==============================] - 12s 118ms/step - loss: 0.4160 - sparse_categorical_accuracy: 0.8682\n",
            "Epoch 9/25\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.3711 - sparse_categorical_accuracy: 0.8816\n",
            "Epoch 00009: loss improved from 0.41599 to 0.37106, saving model to bar_jokes.h5\n",
            "100/100 [==============================] - 12s 119ms/step - loss: 0.3711 - sparse_categorical_accuracy: 0.8816\n",
            "Epoch 10/25\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.3366 - sparse_categorical_accuracy: 0.8920\n",
            "Epoch 00010: loss improved from 0.37106 to 0.33661, saving model to bar_jokes.h5\n",
            "100/100 [==============================] - 12s 117ms/step - loss: 0.3366 - sparse_categorical_accuracy: 0.8920\n",
            "Epoch 11/25\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.3134 - sparse_categorical_accuracy: 0.8988\n",
            "Epoch 00011: loss improved from 0.33661 to 0.31339, saving model to bar_jokes.h5\n",
            "100/100 [==============================] - 12s 119ms/step - loss: 0.3134 - sparse_categorical_accuracy: 0.8988\n",
            "Epoch 12/25\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.2969 - sparse_categorical_accuracy: 0.9035\n",
            "Epoch 00012: loss improved from 0.31339 to 0.29695, saving model to bar_jokes.h5\n",
            "100/100 [==============================] - 12s 117ms/step - loss: 0.2969 - sparse_categorical_accuracy: 0.9035\n",
            "Epoch 13/25\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.2864 - sparse_categorical_accuracy: 0.9066\n",
            "Epoch 00013: loss improved from 0.29695 to 0.28644, saving model to bar_jokes.h5\n",
            "100/100 [==============================] - 12s 117ms/step - loss: 0.2864 - sparse_categorical_accuracy: 0.9066\n",
            "Epoch 14/25\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.2774 - sparse_categorical_accuracy: 0.9091\n",
            "Epoch 00014: loss improved from 0.28644 to 0.27741, saving model to bar_jokes.h5\n",
            "100/100 [==============================] - 12s 116ms/step - loss: 0.2774 - sparse_categorical_accuracy: 0.9091\n",
            "Epoch 15/25\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.2728 - sparse_categorical_accuracy: 0.9102\n",
            "Epoch 00015: loss improved from 0.27741 to 0.27284, saving model to bar_jokes.h5\n",
            "100/100 [==============================] - 12s 118ms/step - loss: 0.2728 - sparse_categorical_accuracy: 0.9102\n",
            "Epoch 16/25\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.2685 - sparse_categorical_accuracy: 0.9115\n",
            "Epoch 00016: loss improved from 0.27284 to 0.26846, saving model to bar_jokes.h5\n",
            "100/100 [==============================] - 12s 117ms/step - loss: 0.2685 - sparse_categorical_accuracy: 0.9115\n",
            "Epoch 17/25\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.2720 - sparse_categorical_accuracy: 0.9102\n",
            "Epoch 00017: loss did not improve from 0.26846\n",
            "100/100 [==============================] - 12s 116ms/step - loss: 0.2720 - sparse_categorical_accuracy: 0.9102\n",
            "Epoch 18/25\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.2699 - sparse_categorical_accuracy: 0.9107\n",
            "Epoch 00018: loss did not improve from 0.26846\n",
            "100/100 [==============================] - 11s 114ms/step - loss: 0.2699 - sparse_categorical_accuracy: 0.9107\n",
            "Epoch 19/25\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.2722 - sparse_categorical_accuracy: 0.9099\n",
            "Epoch 00019: loss did not improve from 0.26846\n",
            "100/100 [==============================] - 12s 116ms/step - loss: 0.2722 - sparse_categorical_accuracy: 0.9099\n",
            "Epoch 20/25\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.2722 - sparse_categorical_accuracy: 0.9095\n",
            "Epoch 00020: loss did not improve from 0.26846\n",
            "100/100 [==============================] - 12s 115ms/step - loss: 0.2722 - sparse_categorical_accuracy: 0.9095\n",
            "Epoch 21/25\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.2726 - sparse_categorical_accuracy: 0.9093\n",
            "Epoch 00021: loss did not improve from 0.26846\n",
            "100/100 [==============================] - 12s 117ms/step - loss: 0.2726 - sparse_categorical_accuracy: 0.9093\n",
            "Epoch 22/25\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.2767 - sparse_categorical_accuracy: 0.9078\n",
            "Epoch 00022: loss did not improve from 0.26846\n",
            "100/100 [==============================] - 12s 118ms/step - loss: 0.2767 - sparse_categorical_accuracy: 0.9078\n",
            "Epoch 23/25\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.2768 - sparse_categorical_accuracy: 0.9078\n",
            "Epoch 00023: loss did not improve from 0.26846\n",
            "100/100 [==============================] - 11s 114ms/step - loss: 0.2768 - sparse_categorical_accuracy: 0.9078\n",
            "Epoch 24/25\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.2767 - sparse_categorical_accuracy: 0.9078\n",
            "Epoch 00024: loss did not improve from 0.26846\n",
            "100/100 [==============================] - 12s 116ms/step - loss: 0.2767 - sparse_categorical_accuracy: 0.9078\n",
            "Epoch 25/25\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.2855 - sparse_categorical_accuracy: 0.9050\n",
            "Epoch 00025: loss did not improve from 0.26846\n",
            "100/100 [==============================] - 12s 118ms/step - loss: 0.2855 - sparse_categorical_accuracy: 0.9050\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb5ae8ef1d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0oBfM4N40OJr",
        "colab_type": "text"
      },
      "source": [
        "## Make Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gu8N8Ye20QPk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "outputId": "93a78be0-2280-4ec2-8d3e-898e0b56fa50"
      },
      "source": [
        "BATCH_SIZE = 5\n",
        "PREDICT_LEN = 250\n",
        "\n",
        "prediction_model = lstm_model(seq_len=1, batch_size=BATCH_SIZE, stateful=True)\n",
        "prediction_model.load_weights(\"bar_jokes.h5\")\n",
        "\n",
        "# Seed models with initial string copied BATCH_SIZE times\n",
        "seed_txt = 'A priest walks into a bar '\n",
        "seed = transform(seed_txt)\n",
        "seed = np.repeat(np.expand_dims(seed, 0), BATCH_SIZE, axis=0)\n",
        "\n",
        "# Prime the state of the model\n",
        "prediction_model.reset_states()\n",
        "for i in range(len(seed_txt) - 1):\n",
        "  prediction_model.predict(seed[:, i:i+1])\n",
        "\n",
        "# Accumulate predictions\n",
        "predictions = [seed[:, -1:]]\n",
        "\n",
        "for i in range(PREDICT_LEN):\n",
        "  last_word = predictions[-1]\n",
        "  next_probits = prediction_model.predict(last_word)[:, 0, :]\n",
        "\n",
        "  # Sample from our output distribution\n",
        "  next_idx = [np.random.choice(256, p=next_probits[i]) for i in range(BATCH_SIZE)]\n",
        "  predictions.append(np.asarray(next_idx, dtype=np.int32))\n",
        "\n",
        "for i in range(BATCH_SIZE):\n",
        "  print(\"Prediction %d\\n\\n\" %i)\n",
        "  p = [predictions[j][i] for j in range(PREDICT_LEN)]\n",
        "  generated = ''.join([chr(c) for c in p])\n",
        "  print(generated)\n",
        "  print()\n",
        "\n",
        "  assert len(generated) == PREDICT_LEN, 'Generated text too short'"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction 0\n",
            "\n",
            "\n",
            " ... He says ouch.\r\n",
            "Niger walks into a bar and he orders over and dips them of whiskey. \"Man, toa know what happened to eat the entire celebrating?\" The panda says, \"I don't know, what did you do that ? ?\" explains the string. \"We don't serve ropes h\n",
            "\n",
            "Prediction 1\n",
            "\n",
            "\n",
            " and trips.\r\n",
            "A man walks into a bar. He walks up to a beautiful woman sitting on his shoulder and ask: \"Why the long face?\". Now! The helium doesn't react. The man walks back to the Good person. He then set them for awhink. He then says, \"oh well the\n",
            "\n",
            "Prediction 2\n",
            "\n",
            "\n",
            " Bartender says \"Hey, you can't have that monkey it taste better if you bought a beer. Its on me. be. Sorry, the frust for my taste I get a piano in the crocodile. It's a Mars bar.\r\n",
            "Man walks into a bar. A roman walks into a bar and ask the bartender\n",
            "\n",
            "Prediction 3\n",
            "\n",
            "\n",
            " where the bartender is Vrhanging every night for a Gin & under the other customer. A man than righter, one of the little start a conversation. I'm going to need a convertables, chickens off our battles rubled and used to change jet stares at the one\n",
            "\n",
            "Prediction 4\n",
            "\n",
            "\n",
            " The bartender says \"look I got a wave with a sore tooth those of my newt.\"\r\n",
            "A Roman walks into a bar OUCH!!!\r\n",
            "Jesus walks into a bar, and the bartender looks at him and says \"High ball hit the genie after that? \"\r\n",
            "A man walks into a bar He tells the\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}